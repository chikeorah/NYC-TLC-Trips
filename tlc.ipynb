{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load up datasets for 3 months\n",
    "This project will be using the first quarter 2024 data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parquet file into dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuseable function to load required columns from parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file and ensure columns are in format to ease processing\n",
    "def process_parquet(parquet_file_path, sample_frac=0.01):\n",
    "    columns_needed = ['request_datetime', 'on_scene_datetime', 'PULocationID', 'DOLocationID', 'trip_time']\n",
    "\n",
    "    # Read the specific columns\n",
    "    df = pd.read_parquet(parquet_file_path, columns=columns_needed)\n",
    "    \n",
    "    # Sample a fraction of the dataframe to reduce memory usage and make processing faster\n",
    "    sampled_df = df.sample(frac=sample_frac)\n",
    "    \n",
    "    # Convert datetime columns\n",
    "    sampled_df['request_datetime'] = pd.to_datetime(sampled_df['request_datetime'])\n",
    "    sampled_df['on_scene_datetime'] = pd.to_datetime(sampled_df['on_scene_datetime'])\n",
    "\n",
    "    # Convert to second precision to save memory\n",
    "    sampled_df['request_datetime'] = sampled_df['request_datetime'].values.astype('datetime64[s]')\n",
    "    sampled_df['on_scene_datetime'] = sampled_df['on_scene_datetime'].values.astype('datetime64[s]')\n",
    "\n",
    "    # Convert int64 to int32\n",
    "    sampled_df['trip_time'] = sampled_df['trip_time'].astype('int32')\n",
    "    \n",
    "    # Calculate the wait_time in seconds\n",
    "    sampled_df['wait_time'] = (sampled_df['on_scene_datetime'] - sampled_df['request_datetime']).dt.total_seconds()\n",
    "    sampled_df['wait_time'] = sampled_df['wait_time'].astype('float32')\n",
    "    \n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 2024\n",
    "trip_jan = process_parquet('data/fhvhv_tripdata_2024-01.parquet')\n",
    "trip_jan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 2024\n",
    "trip_feb = process_parquet('data/fhvhv_tripdata_2024-02.parquet') \n",
    "trip_feb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mar 2024\n",
    "trip_mar = process_parquet('data/fhvhv_tripdata_2024-03.parquet') \n",
    "trip_mar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the three dataframes, ensure the merge is optimised\n",
    "trips = pd.concat([trip_jan, trip_feb, trip_mar], ignore_index=True)\n",
    "\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of dataframe\n",
    "trips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "trips.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls there is more than enough data\n",
    "trips = trips.dropna()\n",
    "trips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait time seems to have some negative values from the min. Using boxplot to investigate more\n",
    "sns.boxplot(x=trips['wait_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of negative wait times.\n",
    "trips[trips['wait_time'] < 0]['wait_time'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop negative wait times\n",
    "trips = trips[trips['wait_time'] >= 0]\n",
    "\n",
    "trips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand the relationship between variables\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(trips.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add external data and features\n",
    "#### 3.1. Add Holidays in NYC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holidays\n",
    "from datetime import date\n",
    "import holidays\n",
    "\n",
    "ny_holidays = holidays.country_holidays('US', subdiv='NY', years=2024)\n",
    "\n",
    "# Load ny_holidays into dataframe, date and holiday name\n",
    "ny_holidays_df = pd.DataFrame.from_dict(ny_holidays, orient='index')\n",
    "ny_holidays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and rename columns\n",
    "ny_holidays_df.reset_index(inplace=True)\n",
    "ny_holidays_df.columns = ['date', 'holiday_name']\n",
    "ny_holidays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert holidays to datetime and create is_holiday flag in the trips dataframe\n",
    "ny_holidays_df.index = pd.to_datetime(ny_holidays_df.index)\n",
    "ny_holidays_df['date'].values.astype('datetime64[s]')\n",
    "trips['is_holiday'] = trips['request_datetime'].dt.date.isin(ny_holidays_df['date']).astype(int)\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping track of memory usage\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Add Time Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour of the day, day of the week, month, year\n",
    "trips['hour'] = trips['request_datetime'].dt.hour\n",
    "trips['week_day'] = trips['request_datetime'].dt.weekday\n",
    "trips['month'] = trips['request_datetime'].dt.month\n",
    "\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define total trip time\n",
    "trips['total_trip_time'] = trips['wait_time'] + trips['trip_time']\n",
    "trips['total_trip_time'] = trips['wait_time'].astype('float32')\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping track of memory usage\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Group into Peak, off-peak and night time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Group request datetime into Peak, Off-Peak and Night\n",
    "    Night: 10pm to 6am\n",
    "    Off-Peak: Weekdays, 10am to 3pm and 7pm to 10pm. Weekends, 6am to 10pm\n",
    "    Peak: Weekdays, 6am to 10am and 3pm to 7pm\n",
    "\"\"\"\n",
    "\n",
    "# Extract hour and day of week\n",
    "hour = trips['hour']\n",
    "week_day = trips['week_day']\n",
    "\n",
    "# is holiday\n",
    "is_holiday = trips['is_holiday'].astype(bool)\n",
    "\n",
    "# Initialize the default group as Night (0)\n",
    "trips['request_time_group'] = 0\n",
    "\n",
    "# Define conditions for Peak (2) and OffPeak (1) times for weekday\n",
    "weekday_mask = week_day < 5\n",
    "\n",
    "peak_mask = (hour >= 6) & (hour < 10) | (hour >= 15) & (hour < 19)\n",
    "off_peak_mask = (hour >= 10) & (hour < 15) | (hour >= 19) & (hour < 22)\n",
    "\n",
    "# For weekend\n",
    "weekend_mask = ~weekday_mask\n",
    "\n",
    "# Apply conditions for weekdays\n",
    "# Pandas is built to work efficiently with data in a vectorized way, meaning it can operate on entire columns (or Series) of data at once without needing an explicit loop\n",
    "# .loc leverages the underlying numpy array to apply the mask to the dataframe without iterating over rows one by one\n",
    "# note that all day during holidays are Off-Peak\n",
    "\n",
    "# If day is not holiday, it will be Peak\n",
    "trips.loc[weekday_mask & peak_mask & ~is_holiday, 'request_time_group'] = 2\n",
    "# If day is holiday, it will be Off-Peak\n",
    "trips.loc[weekday_mask & peak_mask & is_holiday, 'request_time_group'] = 1\n",
    "\n",
    "trips.loc[weekday_mask & off_peak_mask, 'request_time_group'] = 1\n",
    "\n",
    "# Apply conditions for weekends\n",
    "trips.loc[weekend_mask & (hour >= 6) & (hour < 22), 'request_time_group'] = 1\n",
    "\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping track of memory usage\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "trips.drop(['on_scene_datetime'], axis=1, inplace=True)\n",
    "\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping track of memory usage\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. NYC weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Weather data\n",
    "from datetime import datetime \n",
    "from meteostat import Point, Hourly, units  \n",
    "# Set time period \n",
    "start = datetime(2024, 1, 1) \n",
    "end = datetime(2024, 3, 31)  \n",
    "# Create Point for NY\n",
    "location = Point(40.712775, -74.005973)  \n",
    "# Get daily data \n",
    "weather_data = Hourly(location, start, end) \n",
    "weather_data = weather_data.convert(units.imperial) \n",
    "weather_data = weather_data.fetch()\n",
    "\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and convert time to datetime\n",
    "weather_data.reset_index(inplace=True)\n",
    "weather_data.rename(columns={'index': 'time'}, inplace=True)\n",
    "weather_data['time'] = pd.to_datetime(weather_data['time'])\n",
    "\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column to compare with weather time\n",
    "trips['rounded_request_datetime'] = trips['request_datetime'].dt.round('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge trips and weather dataframe on trips[rounded_request_datetime] and weather[time]\n",
    "trips = trips.merge(weather_data, left_on='rounded_request_datetime', right_on='time', how='left')\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded columns\n",
    "trips.drop(['request_datetime', 'rounded_request_datetime', 'trip_time', 'time', 'dwpt', 'rhum', 'wait_time', 'prcp','snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'temp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types\n",
    "trips['request_time_group'] = trips['request_time_group'].astype('int32')\n",
    "trips['coco'] = trips['coco'].astype('float32')\n",
    "\n",
    "# Rename coco to weather_condition_code  \n",
    "trips.rename(columns={'coco': 'weather_condition_code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping track of memory usage\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "trips.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values\n",
    "trips.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "trips.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset shape\n",
    "trips.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. More EDA - Investigating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rounding up columns and converting to int32\n",
    "trips['total_trip_time'] = np.ceil(trips['total_trip_time']).astype('int32')\n",
    "trips['weather_condition_code'] = np.ceil(trips['weather_condition_code']).astype('int32')\n",
    "\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Visualisations to further analyse relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of total_trip_time\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(trips['total_trip_time'], kde=True)\n",
    "plt.title('Distribution of Total Trip Time')\n",
    "plt.xlabel('Total Trip Time (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_trip_time by hour\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='hour', y='total_trip_time', data=trips, errorbar=None)\n",
    "plt.title('Total Trip Time by Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Total Trip Time (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_trip_time by PULocationID\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='PULocationID', y='total_trip_time', data=trips)\n",
    "plt.title('Total Trip Time by Pickup Location')\n",
    "plt.xlabel('Pickup Location ID')\n",
    "plt.ylabel('Total Trip Time (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_trip_time by DOLocationID\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='DOLocationID', y='total_trip_time', data=trips)\n",
    "plt.title('Total Trip Time by Dropoff Location')\n",
    "plt.xlabel('Dropoff Location ID')\n",
    "plt.ylabel('Total Trip Time (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of total_trip_time by weather_condition_code\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='weather_condition_code', y='total_trip_time', data=trips)\n",
    "plt.title('Total Trip Time by Weather Condition Code')\n",
    "plt.xlabel('Weather Condition Code')\n",
    "plt.ylabel('Total Trip Time (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of total_trip_time on holidays vs. non-holidays\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=trips, x='total_trip_time', hue='is_holiday', kde=True, element='step')\n",
    "plt.title('Distribution of Total Trip Time: Holiday vs. Non-Holiday')\n",
    "plt.xlabel('Total Trip Time (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze how the total_trip_time changes across different months, which might reveal seasonal patterns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='month', y='total_trip_time', data=trips, errorbar=None)\n",
    "plt.title('Total Trip Time by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Trip Time (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation heatmap, to check correlation between different variables\n",
    "#results range from -1 to 1 where 1 is perfect correlation and -1 is perfect negative correlation\n",
    "correlation_matrix = trips.corr()\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Machine Learning Models\n",
    "#### 5.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "From the correlation Matrix, there is a low correlation/weak linear relationship between total_trip_time and the other variables. \n",
    "This suggest the use of complex models to capture the non-linear relationship.\n",
    "\n",
    "Starting with a simple linear regression model, even though the correlation is low, the model is able to give a baseline comparison.\n",
    "\"\"\"\n",
    "\n",
    "# Define features and target\n",
    "X = trips.drop('total_trip_time', axis=1)\n",
    "y = trips['total_trip_time']\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy  on test dataset: ', lr_model.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, lr_model.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, lr_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to pickle\n",
    "# import pickle\n",
    "\n",
    "# pickle.dump(lr_model, open('lr_model.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.1. Optimising Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE feature selection\n",
    "sel = RFE(LinearRegression(fit_intercept = True), n_features_to_select=5, step=1)\n",
    "sel = sel.fit(X, y)\n",
    "sel.support_\n",
    "\n",
    "rfe_data = X.columns[sel.support_]\n",
    "\n",
    "X1 = trips[rfe_data]\n",
    "y1 = trips['total_trip_time']\n",
    "\n",
    "#split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "#run linear regression model on the train set\n",
    "lr_model = LinearRegression(fit_intercept = True).fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy  on test dataset: ', lr_model.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, lr_model.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, lr_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "# Create a pipeline for scaling and polynomial features\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Add interaction terms\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model using cross-validation\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy  on test dataset: ', lr_model.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, pipeline.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, lr_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF can capture complex non-linear relationships\n",
    "# Random Forest Regression\n",
    "rf_model = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy  on test dataset: ', rf_model.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, rf_model.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, rf_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.1 Optimising Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'n_estimators': [50, 100, 200],        # Range of trees in the forest\n",
    "    'max_depth': [5, 10, 20, None],        # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],       # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],         # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]             # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Randomized search with fewer iterations (e.g., 10 iterations)\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf_model, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10,  # Number of different combinations to try\n",
    "    cv=3,       # Number of cross-validation folds\n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1,  # Prints progress messages\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "print('Accuracy  on test dataset: ', best_rf.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, best_rf.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, best_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "print('Accuracy  on test dataset: ', best_rf.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, best_rf.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, best_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM can capture complex non-linear relationships\n",
    "# LightGBM Regression\n",
    "lgbm_model = LGBMRegressor(random_state=0)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lgbm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy  on test dataset: ', lgbm_model.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, lgbm_model.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, lgbm_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.1. Optimising LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50],\n",
    "    'max_depth': [-1, 10],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [50, 100]\n",
    "}\n",
    "\n",
    "lgbm_model = LGBMRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(lgbm_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_lgbm = grid_search.best_estimator_\n",
    "y_pred = best_lgbm.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print('Accuracy  on test dataset: ', best_lgbm.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, best_lgbm.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, best_lgbm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'max_depth': [5, 7],\n",
    "    'num_leaves': [20, 31],\n",
    "    'min_child_samples': [20, 50],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'colsample_bytree': [0.7, 0.8]\n",
    "}\n",
    "\n",
    "# Randomized search with early stopping\n",
    "random_search = RandomizedSearchCV(\n",
    "    lgbm_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,  # Number of parameter settings sampled\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model with early stopping\n",
    "random_search.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='mse'\n",
    ")\n",
    "\n",
    "# Best model\n",
    "best_lgbm = random_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_lgbm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy  on test dataset: ', best_lgbm.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, best_lgbm.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, best_lgbm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to DMatrix format (optional but recommended for efficiency)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Simplified hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5],               # Reduced tree depth\n",
    "    'learning_rate': [0.1, 0.01],      # Reasonable learning rates\n",
    "    'n_estimators': [50, 100],         # Fewer trees\n",
    "    'subsample': [0.7, 1],             # Subsample of training data\n",
    "    'colsample_bytree': [0.7, 1],      # Subsample of features\n",
    "}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(random_state=42, n_jobs=2)  # Limit to 2 threads\n",
    "\n",
    "# Initialize GridSearchCV with a smaller search space\n",
    "grid_search = GridSearchCV(\n",
    "    xgb_model, \n",
    "    param_grid, \n",
    "    cv=3,  # Reduce cross-validation folds to 3\n",
    "    scoring='neg_mean_squared_error', \n",
    "    n_jobs=-1,  # Use all available cores for the grid search, but control the cores in XGBoost\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "# # Evaluate the model\n",
    "print('Accuracy  on test dataset: ', best_xgb.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, best_xgb.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, best_xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_train)\n",
    "\n",
    "# Model Accuracy on testing dataset\n",
    "print('The Accuracy  on the testing dataset is: ', reg.score(X_test, y_test) )\n",
    "print('The RMSE  on the testing dataset is: ', np.sqrt(mean_squared_error(y_test,reg.predict(X_test))))\n",
    "print('The MAE  on the testing dataset is: ',mean_absolute_error(y_test,reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing XGBoost Regressor\n",
    "params = { 'max_depth': [3,6,9,12],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.7]}\n",
    "\n",
    "xgbr = xgb.XGBRegressor(seed = 20)\n",
    "\n",
    "clf = GridSearchCV(estimator=xgbr, \n",
    "                   param_grid=params,\n",
    "                   scoring='neg_mean_squared_error', \n",
    "                   verbose=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "\n",
    "# Training the model on best parameters\n",
    "xgbr = xgb.XGBRegressor(seed = 20, colsample_bytree = 0.7, learning_rate= 0.1, max_depth=12, n_estimators=500)\n",
    "xgbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgbr.predict(X_train)\n",
    "\n",
    "# Model Accuracy on testing dataset\n",
    "print('The Accuracy  on the testing dataset is: ', xgbr.score(X_test, y_test) )\n",
    "print('The RMSE  on the testing dataset is: ',np.sqrt(mean_squared_error(y_test,xgbr.predict(X_test))))\n",
    "print('The MAE  on the testing dataset is: ',mean_absolute_error(y_test,xgbr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy  on test dataset: ', best_rf.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, best_rf.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, best_rf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Regression with GridSearchCV\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'max_depth': [-1, 10, 20],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 500]\n",
    "}\n",
    "\n",
    "lgbm_model = LGBMRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(lgbm_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_lgbm = grid_search.best_estimator_\n",
    "y_pred = best_lgbm.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "# Evaluate the model\n",
    "print('Accuracy  on test dataset: ', best_lgbm.score(X_test, y_test) )\n",
    "print('RMSE  on test dataset: ', np.sqrt(mean_squared_error(y_test, best_lgbm.predict(X_test))))\n",
    "print('MAE  on test dataset: ', mean_absolute_error(y_test, best_lgbm.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
